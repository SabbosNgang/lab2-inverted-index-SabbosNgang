{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81d8d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{\\r\\n   \"title\": \"Introduction to Python\",\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{\\r\\n   \"title\": \"Data Analysis with Pandas\",\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{\\r\\n   \"title\": \"Web Development with Flask\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>{\\r\\n   \"title\": \"Machine Learning with Scikit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{\\r\\n   \"title\": \"Data Visualization with Matp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document ID                                            Content\n",
       "0            1  {\\r\\n   \"title\": \"Introduction to Python\",\\r\\n...\n",
       "1            2  {\\r\\n   \"title\": \"Data Analysis with Pandas\",\\...\n",
       "2            3  {\\r\\n   \"title\": \"Web Development with Flask\",...\n",
       "3            4  {\\r\\n   \"title\": \"Machine Learning with Scikit...\n",
       "4            5  {\\r\\n   \"title\": \"Data Visualization with Matp..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV dataset\n",
    "df = pd.read_csv(\"semi_strut.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5ea1871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Introduction, to, Python, John, Doe, Python, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[Data, Analysis, with, Pandas, Jane, Smith, Py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[Web, Development, with, Flask, Mike, Johnson,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[Machine, Learning, with, Scikit-Learn, Emily,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Data, Visualization, with, Matplotlib, Robert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document ID                                               Term\n",
       "0            1  [Introduction, to, Python, John, Doe, Python, ...\n",
       "1            2  [Data, Analysis, with, Pandas, Jane, Smith, Py...\n",
       "2            3  [Web, Development, with, Flask, Mike, Johnson,...\n",
       "3            4  [Machine, Learning, with, Scikit-Learn, Emily,...\n",
       "4            5  [Data, Visualization, with, Matplotlib, Robert..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization function to extract terms from the JSON-like content\n",
    "def tokenize_content(content):\n",
    "    content_dict = json.loads(content)\n",
    "    terms = []\n",
    "\n",
    "    # Remember to extract both \n",
    "    # 1 .Extract terms from various fields (title, keywords, and content)\n",
    "    terms.extend(content_dict.get(\"title\",\"\").split())\n",
    "    terms.extend(content_dict.get(\"author\",\"\").split())\n",
    "    terms.extend(content_dict.get(\"keywords\",[]))\n",
    "    \n",
    "    # 2. Extract terms from sections' titles and content\n",
    "    sections = content_dict.get(\"sections\",[])\n",
    "    for section in sections:\n",
    "        terms.extend(section.get(\"title\",\"\").split())\n",
    "        terms.extend(section.get(\"content\",\"\").split()) \n",
    "\n",
    "    return terms\n",
    "# 3. Tokenize the content and create a new column \"Terms\"\n",
    "df[\"Term\"] = df[\"Content\"].apply(tokenize_content)\n",
    "# 4. Implement a preprocessing function that converts terms to lowercase, removes punctuation, and removes common stop words.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "def preprocess_terms(terms):\n",
    "    terms = [term.lower() for term in terms if term.isalnum()]\n",
    "    # Create another new column \"Terms_preprocessed\"\n",
    "    return terms\n",
    "# 5. you can display the DataFrame\n",
    "df[[\"Document ID\",\"Term\"]]\n",
    "# def tokenize_content(content):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8ea5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131fdcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty inverted index dictionary\n",
    "# Build the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4824b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty inverted index dictionary the extracted terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b929397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform boolean operations on postings lists for Boolean search operations\n",
    "# 1. \"Python\" OR \"Pandas\"\n",
    "# 2. \"Python\" AND \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b64d0674",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Data Science\\IR\\lab2-inverted-index-SabbosNgang\\lab_2.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDocument ID\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mContent\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Create a DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Initialize NLTK resources\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Data%20Science/IR/lab2-inverted-index-SabbosNgang/lab_2.ipynb#X20sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39mwords(\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Ngang Puth Sabbos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    737\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Ngang Puth Sabbos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Ngang Puth Sabbos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Ngang Puth Sabbos\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"Document ID\": [1, 2, 3, 4, 5],\n",
    "    \"Content\": [\n",
    "        {\n",
    "            \"title\": \"Introduction to Python\",\n",
    "            \"author\": \"John Doe\",\n",
    "            \"date\": \"2023-01-15\",\n",
    "            \"keywords\": [\"Python\", \"programming\", \"beginner\"],\n",
    "            \"sections\": [\n",
    "                {\n",
    "                    \"title\": \"Getting Started\",\n",
    "                    \"content\": \"Python is a versatile programming language...\"\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"Basic Syntax\",\n",
    "                    \"content\": \"Python syntax is easy to understand...\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Data Analysis with Pandas\",\n",
    "            \"author\": \"Jane Smith\",\n",
    "            \"date\": \"2023-02-20\",\n",
    "            \"keywords\": [\"Python\", \"Pandas\", \"data analysis\"],\n",
    "            \"sections\": [\n",
    "                {\n",
    "                    \"title\": \"Introduction to Pandas\",\n",
    "                    \"content\": \"Pandas is a popular library for data analysis...\"\n",
    "                },\n",
    "                {\n",
    "                    \"title\": \"DataFrames\",\n",
    "                    \"content\": \"DataFrames are a core data structure in Pandas...\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            # ... (other documents)\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize NLTK resources\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to extract terms from a JSON-like content\n",
    "def tokenize_content(content):\n",
    "    # Initialize the list to store extracted terms\n",
    "    terms = []\n",
    "    extract_terms = []\n",
    "    # Extract terms from various fields (title, keywords, and content)\n",
    "    title_terms = extract_terms(content[\"title\"])\n",
    "    keyword_terms = [term.lower() for term in content[\"keywords\"]]\n",
    "    \n",
    "    # Extract terms from content sections\n",
    "    content_terms = []\n",
    "    for section in content[\"sections\"]:\n",
    "        content_terms.extend(extract_terms(section[\"title\"]))\n",
    "        content_terms.extend(extract_terms(section[\"content\"]))\n",
    "    \n",
    "    # Combine all the terms for this content\n",
    "    terms.extend(title_terms)\n",
    "    terms.extend(keyword_terms)\n",
    "    terms.extend(content_terms)\n",
    "    \n",
    "    return terms\n",
    "\n",
    "# Function to preprocess terms\n",
    "def preprocess_terms(terms):\n",
    "    # Convert terms to lowercase, remove punctuation, and remove stopwords\n",
    "    terms = [term.lower() for term in terms if term.isalnum()]\n",
    "    terms = [stemmer.stem(term) for term in terms if term not in stop_words]\n",
    "    \n",
    "    return terms\n",
    "\n",
    "# Apply tokenization and preprocessing to the Content column\n",
    "df[\"Terms\"] = df[\"Content\"].apply(tokenize_content)\n",
    "df[\"Terms_preprocessed\"] = df[\"Terms\"].apply(preprocess_terms)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
